{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a55759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:01.912740Z",
     "iopub.status.busy": "2025-09-05T09:10:01.912485Z",
     "iopub.status.idle": "2025-09-05T09:10:01.916643Z",
     "shell.execute_reply": "2025-09-05T09:10:01.916094Z"
    },
    "papermill": {
     "duration": 0.01026,
     "end_time": "2025-09-05T09:10:01.917718",
     "exception": false,
     "start_time": "2025-09-05T09:10:01.907458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694cc76",
   "metadata": {
    "papermill": {
     "duration": 0.002802,
     "end_time": "2025-09-05T09:10:01.924001",
     "exception": false,
     "start_time": "2025-09-05T09:10:01.921199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST — MLP warm-up\n",
    "\n",
    "We’ll load MNIST, normalize it, define a small MLP, and run a quick\n",
    "sanity check forward pass to verify shapes before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc35a5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:01.931228Z",
     "iopub.status.busy": "2025-09-05T09:10:01.930978Z",
     "iopub.status.idle": "2025-09-05T09:10:01.933852Z",
     "shell.execute_reply": "2025-09-05T09:10:01.933376Z"
    },
    "papermill": {
     "duration": 0.007599,
     "end_time": "2025-09-05T09:10:01.934790",
     "exception": false,
     "start_time": "2025-09-05T09:10:01.927191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: only run this if your torch/torchvision install is broken.\n",
    "# For GPU on Kaggle (CUDA 12.1 wheels):\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# For CPU-only:\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ec131",
   "metadata": {
    "papermill": {
     "duration": 0.003307,
     "end_time": "2025-09-05T09:10:01.941057",
     "exception": false,
     "start_time": "2025-09-05T09:10:01.937750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports & device\n",
    "\n",
    "We’ll autodetect CUDA and fall back to CPU. The code works either way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf937dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:01.947876Z",
     "iopub.status.busy": "2025-09-05T09:10:01.947665Z",
     "iopub.status.idle": "2025-09-05T09:10:15.021865Z",
     "shell.execute_reply": "2025-09-05T09:10:15.020953Z"
    },
    "papermill": {
     "duration": 13.078907,
     "end_time": "2025-09-05T09:10:15.023281",
     "exception": false,
     "start_time": "2025-09-05T09:10:01.944374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "torchvision: 0.21.0+cu124\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20027f",
   "metadata": {
    "papermill": {
     "duration": 0.0032,
     "end_time": "2025-09-05T09:10:15.029991",
     "exception": false,
     "start_time": "2025-09-05T09:10:15.026791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset & transforms\n",
    "\n",
    "- `ToTensor()` → scales pixels to [0,1] with shape [1, 28, 28].\n",
    "- `Normalize((0.1307,), (0.3081,))` → center/scale using MNIST stats.\n",
    "  (Note the commas: single-element tuples.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e51d0f",
   "metadata": {
    "papermill": {
     "duration": 0.003244,
     "end_time": "2025-09-05T09:10:15.036398",
     "exception": false,
     "start_time": "2025-09-05T09:10:15.033154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we normalize MNIST with `(0.1307,), (0.3081,)`?\n",
    "\n",
    "After `ToTensor()`, MNIST images are scaled to `[0,1]`, but their distribution isn’t centered and doesn’t have unit variance:\n",
    "- Mean pixel value is about **0.1307** (most pixels are dark background).\n",
    "- Standard deviation is about **0.3081**.\n",
    "\n",
    "**Why normalize?**\n",
    "- Centering (subtracting the mean) makes neuron inputs hover around zero, which helps gradients flow and speeds up learning.\n",
    "- Scaling (dividing by the std) puts features on a comparable scale, making optimization more stable and less sensitive to learning rates.\n",
    "\n",
    "**Why those exact numbers?**\n",
    "- They are the empirical mean and std of the MNIST training set computed over all pixels.\n",
    "- Using dataset-specific stats is better than generic choices (like 0.5/0.5) because it matches the true data distribution.\n",
    "\n",
    "**Why the tuples — and why the comma is so important?**\n",
    "- `Normalize` expects a *sequence* (list or tuple) with one value per channel.\n",
    "- MNIST has 1 channel → we need one mean and one std → a 1-element tuple.\n",
    "- In Python:\n",
    "  - `(0.3081,)` → a tuple containing one float ✅\n",
    "  - `(0.3081)` → just a float ❌\n",
    "- If you forget the comma, you pass a float instead of a tuple. That breaks the shape handling inside `Normalize` and can lead to confusing errors (like “std evaluated to zero”).\n",
    "\n",
    "**What if we skip normalization?**\n",
    "- The model may still learn (MNIST is simple), but:\n",
    "  - Training is slower.\n",
    "  - Optimization is less stable.\n",
    "  - Accuracy may plateau lower.\n",
    "- For harder datasets (like CIFAR or ImageNet), skipping normalization can mean the model fails to learn at all.\n",
    "\n",
    "**TL;DR**\n",
    "Normalization with `(0.1307,), (0.3081,)` standardizes MNIST inputs to zero-like mean and unit-like variance.  \n",
    "The trailing comma is crucial because it makes those values tuples, not plain floats, which is exactly what `Normalize` expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770fda83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:15.043736Z",
     "iopub.status.busy": "2025-09-05T09:10:15.043372Z",
     "iopub.status.idle": "2025-09-05T09:10:17.248743Z",
     "shell.execute_reply": "2025-09-05T09:10:17.247853Z"
    },
    "papermill": {
     "duration": 2.210574,
     "end_time": "2025-09-05T09:10:17.250005",
     "exception": false,
     "start_time": "2025-09-05T09:10:15.039431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 37.8MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.04MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.77MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.46MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one sample: torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "x0, y0 = train_mnist[0]\n",
    "print(\"one sample:\", x0.shape, y0)  # torch.Size([1, 28, 28]) label_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9241004",
   "metadata": {
    "papermill": {
     "duration": 0.003953,
     "end_time": "2025-09-05T09:10:17.258396",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.254443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "A simple fully-connected classifier:\n",
    "- Flatten 28×28 → 784\n",
    "- Hidden: 300 → 300 with LeakyReLU\n",
    "- Output: 10 logits (no Softmax; CrossEntropyLoss expects logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac21ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:17.268228Z",
     "iopub.status.busy": "2025-09-05T09:10:17.267418Z",
     "iopub.status.idle": "2025-09-05T09:10:17.278485Z",
     "shell.execute_reply": "2025-09-05T09:10:17.277857Z"
    },
    "papermill": {
     "duration": 0.016962,
     "end_time": "2025-09-05T09:10:17.279679",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.262717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# In PyTorch, p.numel() returns the number of elements (scalars) in the tensor p.\n",
    "\n",
    "p = torch.randn(3, 4)   # shape [3,4]\n",
    "print(p.numel())        # 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe97bd2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:17.288255Z",
     "iopub.status.busy": "2025-09-05T09:10:17.288029Z",
     "iopub.status.idle": "2025-09-05T09:10:17.513239Z",
     "shell.execute_reply": "2025-09-05T09:10:17.512227Z"
    },
    "papermill": {
     "duration": 0.230736,
     "end_time": "2025-09-05T09:10:17.514554",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.283818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 328810\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 10)  # logits\n",
    ").to(device)\n",
    "\n",
    "sum_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"model params:\", sum_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e12cd",
   "metadata": {
    "papermill": {
     "duration": 0.003891,
     "end_time": "2025-09-05T09:10:17.522309",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.518418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check (single example)\n",
    "\n",
    "Flatten to 784 features, forward once, confirm output shape [1, 10].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f0477e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:17.530852Z",
     "iopub.status.busy": "2025-09-05T09:10:17.530598Z",
     "iopub.status.idle": "2025-09-05T09:10:17.736713Z",
     "shell.execute_reply": "2025-09-05T09:10:17.735861Z"
    },
    "papermill": {
     "duration": 0.212005,
     "end_time": "2025-09-05T09:10:17.738081",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.526076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single forward shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "digit, cls = train_mnist[0]\n",
    "digit = digit.to(device).view(1, 28*28)  # add batch dim = 1\n",
    "with torch.no_grad():\n",
    "    out = model(digit)\n",
    "print(\"single forward shape:\", out.shape)  # torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19312b8",
   "metadata": {
    "papermill": {
     "duration": 0.004188,
     "end_time": "2025-09-05T09:10:17.746708",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.742520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check with dataset loop (first item only)\n",
    "\n",
    "Iterate the dataset, move to device, flatten, run model, print shape, break.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea71d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:17.755363Z",
     "iopub.status.busy": "2025-09-05T09:10:17.755120Z",
     "iopub.status.idle": "2025-09-05T09:10:17.761260Z",
     "shell.execute_reply": "2025-09-05T09:10:17.760537Z"
    },
    "papermill": {
     "duration": 0.012097,
     "end_time": "2025-09-05T09:10:17.762486",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.750389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for digit, cls in train_mnist:\n",
    "    digit = digit.to(device)\n",
    "    digit = digit.view(digit.shape[0], 28*28)\n",
    "    with torch.no_grad():\n",
    "        print(model(digit).shape)  # expected: torch.Size([1, 10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ece81a",
   "metadata": {
    "papermill": {
     "duration": 0.003474,
     "end_time": "2025-09-05T09:10:17.770097",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.766623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `digit.view(digit.shape[0], 28*28)`?\n",
    "\n",
    "Each MNIST image comes as a tensor of shape `[B, 1, 28, 28]`:\n",
    "- `B` = batch size  \n",
    "- `1` = number of channels (grayscale)  \n",
    "- `28 × 28` = image height and width  \n",
    "\n",
    "Our model starts with a `Linear(28*28, 300)` layer, which expects a\n",
    "**flat vector of 784 features per image**, not a 2D grid.\n",
    "\n",
    "The call\n",
    "\n",
    "``` python\n",
    "digit = digit.view(digit.shape[0], 28*28)\n",
    "```\n",
    "\n",
    "does two things:\n",
    "1. Keeps the batch dimension (`digit.shape[0]`).\n",
    "2. Flattens each `[1,28,28]` image into a single vector `[784]`.\n",
    "\n",
    "So:\n",
    "- Before: `[B, 1, 28, 28]`  \n",
    "- After:  `[B, 784]`  \n",
    "\n",
    "This reshaping step bridges the gap between image-shaped data and the\n",
    "fully connected (dense) layers of our MLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a97c52",
   "metadata": {
    "papermill": {
     "duration": 0.003511,
     "end_time": "2025-09-05T09:10:17.777611",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.774100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloaders\n",
    "\n",
    "We’ll iterate in mini-batches for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ba78f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:10:17.786424Z",
     "iopub.status.busy": "2025-09-05T09:10:17.786220Z",
     "iopub.status.idle": "2025-09-05T09:10:17.792746Z",
     "shell.execute_reply": "2025-09-05T09:10:17.791987Z"
    },
    "papermill": {
     "duration": 0.012379,
     "end_time": "2025-09-05T09:10:17.793844",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.781465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 162)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "batch_size = 62 \n",
    "train_dl = DataLoader(\n",
    "    train_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2, \n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ae2bf",
   "metadata": {
    "papermill": {
     "duration": 0.003866,
     "end_time": "2025-09-05T09:10:17.802175",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.798309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding `DataLoader` arguments\n",
    "\n",
    "When we wrap our MNIST datasets in `DataLoader`, we specify a few\n",
    "important options:\n",
    "\n",
    "- **`batch_size=64`**  \n",
    "  - How many samples to group together in one batch.  \n",
    "  - Instead of returning a single `[1, 28, 28]` image, the loader\n",
    "    returns `[64, 1, 28, 28]` tensors.  \n",
    "  - Larger batch sizes improve GPU utilization and give smoother\n",
    "    gradient estimates, but also use more memory.  \n",
    "  - On CPU, smaller batches can be more practical to keep things fast\n",
    "    and memory-efficient.\n",
    "\n",
    "- **`shuffle=True` (for training)**  \n",
    "  - Each epoch, the training data is shuffled.  \n",
    "  - Prevents the model from simply memorizing the order of the data.  \n",
    "  - Helps generalization because each mini-batch looks different each\n",
    "    epoch.  \n",
    "  - For evaluation (`test_dl`), we use `shuffle=False` so results are\n",
    "    deterministic and ordered.\n",
    "\n",
    "- **`num_workers=2`**  \n",
    "  - Number of subprocesses used to load data in parallel.  \n",
    "  - `0` means load in the main process (slower).  \n",
    "  - On CPU or GPU, having a few workers (like 2–4) allows data to be\n",
    "    prefetched while the model is training on the previous batch,\n",
    "    keeping the pipeline efficient.  \n",
    "  - On Kaggle, small values (like 2) are often safe.\n",
    "\n",
    "- **`pin_memory=(device==\"cuda\")`**  \n",
    "  - *Pinned (page-locked) memory* speeds up data transfer from CPU RAM\n",
    "    to GPU memory.  \n",
    "  - If `device==\"cuda\"`, we set `pin_memory=True` so each batch can be\n",
    "    moved to GPU more efficiently with `.to(\"cuda\")`.  \n",
    "  - If `device==\"cpu\"`, this option does nothing and can safely remain\n",
    "    `False`.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "- Training loader: `batch_size=64`, `shuffle=True`  \n",
    "- Test loader: `batch_size=64`, `shuffle=False`  \n",
    "- Use a few `num_workers` to overlap data loading with computation.  \n",
    "- Enable `pin_memory` only when training on CUDA for faster CPU→GPU\n",
    "  transfers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa10cd6",
   "metadata": {
    "papermill": {
     "duration": 0.00386,
     "end_time": "2025-09-05T09:10:17.810123",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.806263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4dcc3",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2025-09-05T09:10:17.817862",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.814162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8451848",
   "metadata": {
    "papermill": {
     "duration": 0.00396,
     "end_time": "2025-09-05T09:10:17.826046",
     "exception": false,
     "start_time": "2025-09-05T09:10:17.822086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.010324,
   "end_time": "2025-09-05T09:10:20.038136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T09:09:56.027812",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
