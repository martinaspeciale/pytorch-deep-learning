{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7bce45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:18.476916Z",
     "iopub.status.busy": "2025-09-05T09:48:18.476719Z",
     "iopub.status.idle": "2025-09-05T09:48:18.480393Z",
     "shell.execute_reply": "2025-09-05T09:48:18.479717Z"
    },
    "papermill": {
     "duration": 0.011189,
     "end_time": "2025-09-05T09:48:18.481575",
     "exception": false,
     "start_time": "2025-09-05T09:48:18.470386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15dad2",
   "metadata": {
    "papermill": {
     "duration": 0.004027,
     "end_time": "2025-09-05T09:48:18.490177",
     "exception": false,
     "start_time": "2025-09-05T09:48:18.486150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST — MLP warm-up\n",
    "\n",
    "We’ll load MNIST, normalize it, define a small MLP, and run a quick\n",
    "sanity check forward pass to verify shapes before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6210f75f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:18.499568Z",
     "iopub.status.busy": "2025-09-05T09:48:18.498986Z",
     "iopub.status.idle": "2025-09-05T09:48:18.502111Z",
     "shell.execute_reply": "2025-09-05T09:48:18.501471Z"
    },
    "papermill": {
     "duration": 0.008806,
     "end_time": "2025-09-05T09:48:18.503201",
     "exception": false,
     "start_time": "2025-09-05T09:48:18.494395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: only run this if your torch/torchvision install is broken.\n",
    "# For GPU on Kaggle (CUDA 12.1 wheels):\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# For CPU-only:\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7c655",
   "metadata": {
    "papermill": {
     "duration": 0.003972,
     "end_time": "2025-09-05T09:48:18.511372",
     "exception": false,
     "start_time": "2025-09-05T09:48:18.507400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports & device\n",
    "\n",
    "We’ll autodetect CUDA and fall back to CPU. The code works either way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632a42b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:18.520863Z",
     "iopub.status.busy": "2025-09-05T09:48:18.520335Z",
     "iopub.status.idle": "2025-09-05T09:48:27.446265Z",
     "shell.execute_reply": "2025-09-05T09:48:27.445409Z"
    },
    "papermill": {
     "duration": 8.932033,
     "end_time": "2025-09-05T09:48:27.447538",
     "exception": false,
     "start_time": "2025-09-05T09:48:18.515505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "torchvision: 0.21.0+cu124\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a940be",
   "metadata": {
    "papermill": {
     "duration": 0.004122,
     "end_time": "2025-09-05T09:48:27.456371",
     "exception": false,
     "start_time": "2025-09-05T09:48:27.452249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset & transforms\n",
    "\n",
    "- `ToTensor()` → scales pixels to [0,1] with shape [1, 28, 28].\n",
    "- `Normalize((0.1307,), (0.3081,))` → center/scale using MNIST stats.\n",
    "  (Note the commas: single-element tuples.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf338a",
   "metadata": {
    "papermill": {
     "duration": 0.004042,
     "end_time": "2025-09-05T09:48:27.465233",
     "exception": false,
     "start_time": "2025-09-05T09:48:27.461191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we normalize MNIST with `(0.1307,), (0.3081,)`?\n",
    "\n",
    "After `ToTensor()`, MNIST images are scaled to `[0,1]`, but their distribution isn’t centered and doesn’t have unit variance:\n",
    "- Mean pixel value is about **0.1307** (most pixels are dark background).\n",
    "- Standard deviation is about **0.3081**.\n",
    "\n",
    "**Why normalize?**\n",
    "- Centering (subtracting the mean) makes neuron inputs hover around zero, which helps gradients flow and speeds up learning.\n",
    "- Scaling (dividing by the std) puts features on a comparable scale, making optimization more stable and less sensitive to learning rates.\n",
    "\n",
    "**Why those exact numbers?**\n",
    "- They are the empirical mean and std of the MNIST training set computed over all pixels.\n",
    "- Using dataset-specific stats is better than generic choices (like 0.5/0.5) because it matches the true data distribution.\n",
    "\n",
    "**Why the tuples — and why the comma is so important?**\n",
    "- `Normalize` expects a *sequence* (list or tuple) with one value per channel.\n",
    "- MNIST has 1 channel → we need one mean and one std → a 1-element tuple.\n",
    "- In Python:\n",
    "  - `(0.3081,)` → a tuple containing one float ✅\n",
    "  - `(0.3081)` → just a float ❌\n",
    "- If you forget the comma, you pass a float instead of a tuple. That breaks the shape handling inside `Normalize` and can lead to confusing errors (like “std evaluated to zero”).\n",
    "\n",
    "**What if we skip normalization?**\n",
    "- The model may still learn (MNIST is simple), but:\n",
    "  - Training is slower.\n",
    "  - Optimization is less stable.\n",
    "  - Accuracy may plateau lower.\n",
    "- For harder datasets (like CIFAR or ImageNet), skipping normalization can mean the model fails to learn at all.\n",
    "\n",
    "**TL;DR**\n",
    "Normalization with `(0.1307,), (0.3081,)` standardizes MNIST inputs to zero-like mean and unit-like variance.  \n",
    "The trailing comma is crucial because it makes those values tuples, not plain floats, which is exactly what `Normalize` expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3455532c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:27.474525Z",
     "iopub.status.busy": "2025-09-05T09:48:27.474240Z",
     "iopub.status.idle": "2025-09-05T09:48:30.200431Z",
     "shell.execute_reply": "2025-09-05T09:48:30.199684Z"
    },
    "papermill": {
     "duration": 2.732151,
     "end_time": "2025-09-05T09:48:30.201589",
     "exception": false,
     "start_time": "2025-09-05T09:48:27.469438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 37.9MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.29MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one sample: torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "x0, y0 = train_mnist[0]\n",
    "print(\"one sample:\", x0.shape, y0)  # torch.Size([1, 28, 28]) label_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e49d7",
   "metadata": {
    "papermill": {
     "duration": 0.004648,
     "end_time": "2025-09-05T09:48:30.211438",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.206790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "A simple fully-connected classifier:\n",
    "- Flatten 28×28 → 784\n",
    "- Hidden: 300 → 300 with LeakyReLU\n",
    "- Output: 10 logits (no Softmax; CrossEntropyLoss expects logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2903524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.221778Z",
     "iopub.status.busy": "2025-09-05T09:48:30.221562Z",
     "iopub.status.idle": "2025-09-05T09:48:30.228809Z",
     "shell.execute_reply": "2025-09-05T09:48:30.228261Z"
    },
    "papermill": {
     "duration": 0.013581,
     "end_time": "2025-09-05T09:48:30.229793",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.216212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# In PyTorch, p.numel() returns the number of elements (scalars) in the tensor p.\n",
    "\n",
    "p = torch.randn(3, 4)   # shape [3,4]\n",
    "print(p.numel())        # 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fe989d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.240428Z",
     "iopub.status.busy": "2025-09-05T09:48:30.240220Z",
     "iopub.status.idle": "2025-09-05T09:48:30.428390Z",
     "shell.execute_reply": "2025-09-05T09:48:30.427672Z"
    },
    "papermill": {
     "duration": 0.194879,
     "end_time": "2025-09-05T09:48:30.429602",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.234723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 328810\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 10)  # logits\n",
    ").to(device)\n",
    "\n",
    "sum_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"model params:\", sum_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ef01b",
   "metadata": {
    "papermill": {
     "duration": 0.004875,
     "end_time": "2025-09-05T09:48:30.439782",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.434907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check (single example)\n",
    "\n",
    "Flatten to 784 features, forward once, confirm output shape [1, 10].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e01877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.450471Z",
     "iopub.status.busy": "2025-09-05T09:48:30.450242Z",
     "iopub.status.idle": "2025-09-05T09:48:30.589284Z",
     "shell.execute_reply": "2025-09-05T09:48:30.588626Z"
    },
    "papermill": {
     "duration": 0.145864,
     "end_time": "2025-09-05T09:48:30.590483",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.444619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single forward shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "digit, cls = train_mnist[0]\n",
    "digit = digit.to(device).view(1, 28*28)  # add batch dim = 1\n",
    "with torch.no_grad():\n",
    "    out = model(digit)\n",
    "print(\"single forward shape:\", out.shape)  # torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c13ad",
   "metadata": {
    "papermill": {
     "duration": 0.004822,
     "end_time": "2025-09-05T09:48:30.600617",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.595795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check with dataset loop (first item only)\n",
    "\n",
    "Iterate the dataset, move to device, flatten, run model, print shape, break.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96b05d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.611636Z",
     "iopub.status.busy": "2025-09-05T09:48:30.611229Z",
     "iopub.status.idle": "2025-09-05T09:48:30.616632Z",
     "shell.execute_reply": "2025-09-05T09:48:30.616060Z"
    },
    "papermill": {
     "duration": 0.011805,
     "end_time": "2025-09-05T09:48:30.617599",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.605794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for digit, cls in train_mnist:\n",
    "    digit = digit.to(device)\n",
    "    digit = digit.view(digit.shape[0], 28*28)\n",
    "    with torch.no_grad():\n",
    "        print(model(digit).shape)  # expected: torch.Size([1, 10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ceffb",
   "metadata": {
    "papermill": {
     "duration": 0.004784,
     "end_time": "2025-09-05T09:48:30.627569",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.622785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `digit.view(digit.shape[0], 28*28)`?\n",
    "\n",
    "Each MNIST image comes as a tensor of shape `[B, 1, 28, 28]`:\n",
    "- `B` = batch size  \n",
    "- `1` = number of channels (grayscale)  \n",
    "- `28 × 28` = image height and width  \n",
    "\n",
    "Our model starts with a `Linear(28*28, 300)` layer, which expects a\n",
    "**flat vector of 784 features per image**, not a 2D grid.\n",
    "\n",
    "The call\n",
    "\n",
    "``` python\n",
    "digit = digit.view(digit.shape[0], 28*28)\n",
    "```\n",
    "\n",
    "does two things:\n",
    "1. Keeps the batch dimension (`digit.shape[0]`).\n",
    "2. Flattens each `[1,28,28]` image into a single vector `[784]`.\n",
    "\n",
    "So:\n",
    "- Before: `[B, 1, 28, 28]`  \n",
    "- After:  `[B, 784]`  \n",
    "\n",
    "This reshaping step bridges the gap between image-shaped data and the\n",
    "fully connected (dense) layers of our MLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15d8c2",
   "metadata": {
    "papermill": {
     "duration": 0.004735,
     "end_time": "2025-09-05T09:48:30.637265",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.632530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloaders\n",
    "\n",
    "We’ll iterate in mini-batches for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4cb78b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.648266Z",
     "iopub.status.busy": "2025-09-05T09:48:30.647686Z",
     "iopub.status.idle": "2025-09-05T09:48:30.653546Z",
     "shell.execute_reply": "2025-09-05T09:48:30.653019Z"
    },
    "papermill": {
     "duration": 0.012288,
     "end_time": "2025-09-05T09:48:30.654508",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.642220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 162)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "batch_size = 62 \n",
    "train_dl = DataLoader(\n",
    "    train_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2, \n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f719ca",
   "metadata": {
    "papermill": {
     "duration": 0.00595,
     "end_time": "2025-09-05T09:48:30.665558",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.659608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding `DataLoader` arguments\n",
    "\n",
    "When we wrap our MNIST datasets in `DataLoader`, we specify a few\n",
    "important options:\n",
    "\n",
    "- **`batch_size=64`**  \n",
    "  - How many samples to group together in one batch.  \n",
    "  - Instead of returning a single `[1, 28, 28]` image, the loader\n",
    "    returns `[64, 1, 28, 28]` tensors.  \n",
    "  - Larger batch sizes improve GPU utilization and give smoother\n",
    "    gradient estimates, but also use more memory.  \n",
    "  - On CPU, smaller batches can be more practical to keep things fast\n",
    "    and memory-efficient.\n",
    "\n",
    "- **`shuffle=True` (for training)**  \n",
    "  - Each epoch, the training data is shuffled.  \n",
    "  - Prevents the model from simply memorizing the order of the data.  \n",
    "  - Helps generalization because each mini-batch looks different each\n",
    "    epoch.  \n",
    "  - For evaluation (`test_dl`), we use `shuffle=False` so results are\n",
    "    deterministic and ordered.\n",
    "\n",
    "- **`num_workers=2`**  \n",
    "  - Number of subprocesses used to load data in parallel.  \n",
    "  - `0` means load in the main process (slower).  \n",
    "  - On CPU or GPU, having a few workers (like 2–4) allows data to be\n",
    "    prefetched while the model is training on the previous batch,\n",
    "    keeping the pipeline efficient.  \n",
    "  - On Kaggle, small values (like 2) are often safe.\n",
    "\n",
    "- **`pin_memory=(device==\"cuda\")`**  \n",
    "  - *Pinned (page-locked) memory* speeds up data transfer from CPU RAM\n",
    "    to GPU memory.  \n",
    "  - If `device==\"cuda\"`, we set `pin_memory=True` so each batch can be\n",
    "    moved to GPU more efficiently with `.to(\"cuda\")`.  \n",
    "  - If `device==\"cpu\"`, this option does nothing and can safely remain\n",
    "    `False`.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "- Training loader: `batch_size=64`, `shuffle=True`  \n",
    "- Test loader: `batch_size=64`, `shuffle=False`  \n",
    "- Use a few `num_workers` to overlap data loading with computation.  \n",
    "- Enable `pin_memory` only when training on CUDA for faster CPU→GPU\n",
    "  transfers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390865f1",
   "metadata": {
    "papermill": {
     "duration": 0.004826,
     "end_time": "2025-09-05T09:48:30.675438",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.670612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss & Optimizer\n",
    "\n",
    "- **Loss:** `CrossEntropyLoss` compares the model’s **logits** to the\n",
    "  ground-truth class indices. It internally applies `log_softmax`, so\n",
    "  we **do not** put a `Softmax` layer in the model.\n",
    "- **Optimizer:** `Adam` with a standard learning rate (1e-3) works well\n",
    "  for this small MLP. It adapts per-parameter step sizes and usually\n",
    "  converges faster than plain SGD.\n",
    "- **Seed:** we set a manual seed for reproducibility (weight init and\n",
    "  the Adam state).\n",
    "- This works the same on **CPU or CUDA**; no device-specific changes are\n",
    "  needed for defining the loss/optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1574e96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.686152Z",
     "iopub.status.busy": "2025-09-05T09:48:30.685811Z",
     "iopub.status.idle": "2025-09-05T09:48:30.694127Z",
     "shell.execute_reply": "2025-09-05T09:48:30.693517Z"
    },
    "papermill": {
     "duration": 0.014754,
     "end_time": "2025-09-05T09:48:30.695173",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.680419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(loss_fn)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5424502",
   "metadata": {
    "papermill": {
     "duration": 0.004857,
     "end_time": "2025-09-05T09:48:30.705155",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.700298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Loop \n",
    "We train for a few epochs using mini-batches:\n",
    "- Switch the model to `train()` mode (enables layers like dropout/batchnorm if present)\n",
    "- Move each batch to the selected `device` (CPU or CUDA)\n",
    "- **Flatten** `[B, 1, 28, 28] → [B, 784]` before the first linear layer.\n",
    "- Forward → compute **CrossEntropyLoss** on logits → backprop → optimizer step.\n",
    "- Track running loss and accuracy for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54813117",
   "metadata": {
    "papermill": {
     "duration": 0.004822,
     "end_time": "2025-09-05T09:48:30.714998",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.710176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. `train_dl`\n",
    "   * this is a DataLoader we created from train_mnist\n",
    "   * each iteration returns a mini-batch of samples\n",
    "   * by default, it yields a tuple: `(batch_of_images, batch_of_labels)`\n",
    "3. `tqdm(train_dl, desc= ...)`\n",
    "   * `tqdm` wraps the DataLoader so we get a live progress bar while looping\n",
    "   * the desc string is shown at the start of the bar \n",
    "5. `for x, y in bar:`\n",
    "   * on each loop:\n",
    "        - `x` = a batch of images, shape [B,1,28,28]\n",
    "        - `y` = the corresponding batch of labels, shape [B] (each entry is an integer 0-9 for the digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05021e7",
   "metadata": {
    "papermill": {
     "duration": 0.004832,
     "end_time": "2025-09-05T09:48:30.724921",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.720089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we flatten `x` but not `y`?\n",
    "\n",
    "- **`x` (the images)**  \n",
    "  - Each batch arrives from the `DataLoader` with shape `[B, 1, 28, 28]`  \n",
    "    (`B` = batch size, `1` = grayscale channel, `28×28` = pixels).  \n",
    "  - Our model begins with a linear layer `Linear(28*28, 300)`, which\n",
    "    expects a **2D tensor** of shape `[B, 784]`.  \n",
    "  - Therefore, we flatten each image with  \n",
    "    `x = x.view(B, 28*28)` so every image becomes a 784-dimensional\n",
    "    vector, while preserving the batch dimension.\n",
    "\n",
    "- **`y` (the labels)**  \n",
    "  - Labels are already a 1D tensor of integers with shape `[B]`\n",
    "    (e.g. `[5, 0, 4, 1, 9, ...]`).  \n",
    "  - `CrossEntropyLoss` expects predictions as `[B, num_classes]`\n",
    "    (logits) and targets as `[B]` (integer class indices).  \n",
    "  - Since `y` is already in the right format, we **don’t reshape it**.\n",
    "\n",
    "**In short:**  \n",
    "- Flatten `x` because the network needs flat input vectors.  \n",
    "- Leave `y` as is because it already contains class indices in the\n",
    "expected shape for the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a17d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:48:30.735683Z",
     "iopub.status.busy": "2025-09-05T09:48:30.735499Z",
     "iopub.status.idle": "2025-09-05T09:49:05.993968Z",
     "shell.execute_reply": "2025-09-05T09:49:05.993010Z"
    },
    "papermill": {
     "duration": 35.265521,
     "end_time": "2025-09-05T09:49:05.995461",
     "exception": false,
     "start_time": "2025-09-05T09:48:30.729940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/3: 100%|██████████| 968/968 [00:09<00:00, 106.90it/s, acc=0.935, loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.2141, acc=0.9347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 968/968 [00:08<00:00, 110.19it/s, acc=0.972, loss=0.0904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.0894, acc=0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 968/968 [00:08<00:00, 111.99it/s, acc=0.979, loss=0.024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.0648, acc=0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 968/968 [00:08<00:00, 110.53it/s, acc=0.983, loss=0.0639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.0511, acc=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "epochs = 3 \n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train() \n",
    "\n",
    "    running_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    bar = tqdm(\n",
    "        train_dl, \n",
    "        desc=f\"Epoch {epoch}/{epochs}\"\n",
    "    )\n",
    "\n",
    "    for x, y in bar:\n",
    "        # move to device and flatten \n",
    "        x = x.to(device).view(x.shape[0], 28*28)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward + loss \n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # backprop + step \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # metrics \n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1) \n",
    "        correct += (preds==y).sum().item() \n",
    "        total += y.numel() \n",
    "\n",
    "        bar.set_postfix(\n",
    "            loss=loss.item(), \n",
    "            acc=(correct / total)\n",
    "        )\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total \n",
    "    epoch_acc = correct / total \n",
    "    print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, acc={epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4757f4",
   "metadata": {
    "papermill": {
     "duration": 0.175828,
     "end_time": "2025-09-05T09:49:06.339461",
     "exception": false,
     "start_time": "2025-09-05T09:49:06.163633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbd2b6",
   "metadata": {
    "papermill": {
     "duration": 0.161762,
     "end_time": "2025-09-05T09:49:06.664667",
     "exception": false,
     "start_time": "2025-09-05T09:49:06.502905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76eca9",
   "metadata": {
    "papermill": {
     "duration": 0.162676,
     "end_time": "2025-09-05T09:49:06.989633",
     "exception": false,
     "start_time": "2025-09-05T09:49:06.826957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49f15",
   "metadata": {
    "papermill": {
     "duration": 0.205425,
     "end_time": "2025-09-05T09:49:07.360368",
     "exception": false,
     "start_time": "2025-09-05T09:49:07.154943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb02be56",
   "metadata": {
    "papermill": {
     "duration": 0.159479,
     "end_time": "2025-09-05T09:49:07.681419",
     "exception": false,
     "start_time": "2025-09-05T09:49:07.521940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f252c",
   "metadata": {
    "papermill": {
     "duration": 0.160245,
     "end_time": "2025-09-05T09:49:08.003841",
     "exception": false,
     "start_time": "2025-09-05T09:49:07.843596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac240aaa",
   "metadata": {
    "papermill": {
     "duration": 0.159432,
     "end_time": "2025-09-05T09:49:08.321566",
     "exception": false,
     "start_time": "2025-09-05T09:49:08.162134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a68f8",
   "metadata": {
    "papermill": {
     "duration": 0.169257,
     "end_time": "2025-09-05T09:49:08.700889",
     "exception": false,
     "start_time": "2025-09-05T09:49:08.531632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6125464",
   "metadata": {
    "papermill": {
     "duration": 0.166717,
     "end_time": "2025-09-05T09:49:09.037510",
     "exception": false,
     "start_time": "2025-09-05T09:49:08.870793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de26cc",
   "metadata": {
    "papermill": {
     "duration": 0.205495,
     "end_time": "2025-09-05T09:49:09.402145",
     "exception": false,
     "start_time": "2025-09-05T09:49:09.196650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e487b8",
   "metadata": {
    "papermill": {
     "duration": 0.175436,
     "end_time": "2025-09-05T09:49:09.737981",
     "exception": false,
     "start_time": "2025-09-05T09:49:09.562545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77b9fa",
   "metadata": {
    "papermill": {
     "duration": 0.16991,
     "end_time": "2025-09-05T09:49:10.091897",
     "exception": false,
     "start_time": "2025-09-05T09:49:09.921987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14081afd",
   "metadata": {
    "papermill": {
     "duration": 0.159007,
     "end_time": "2025-09-05T09:49:10.408825",
     "exception": false,
     "start_time": "2025-09-05T09:49:10.249818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b427fe",
   "metadata": {
    "papermill": {
     "duration": 0.160935,
     "end_time": "2025-09-05T09:49:10.777336",
     "exception": false,
     "start_time": "2025-09-05T09:49:10.616401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a895e",
   "metadata": {
    "papermill": {
     "duration": 0.157825,
     "end_time": "2025-09-05T09:49:11.095351",
     "exception": false,
     "start_time": "2025-09-05T09:49:10.937526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.388938,
   "end_time": "2025-09-05T09:49:13.617270",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T09:48:14.228332",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
