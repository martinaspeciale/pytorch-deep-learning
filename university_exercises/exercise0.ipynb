{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fb21ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:39.979238Z",
     "iopub.status.busy": "2025-09-05T09:20:39.978999Z",
     "iopub.status.idle": "2025-09-05T09:20:39.982818Z",
     "shell.execute_reply": "2025-09-05T09:20:39.982121Z"
    },
    "papermill": {
     "duration": 0.009595,
     "end_time": "2025-09-05T09:20:39.983962",
     "exception": false,
     "start_time": "2025-09-05T09:20:39.974367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fe708",
   "metadata": {
    "papermill": {
     "duration": 0.002795,
     "end_time": "2025-09-05T09:20:39.990309",
     "exception": false,
     "start_time": "2025-09-05T09:20:39.987514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST — MLP warm-up\n",
    "\n",
    "We’ll load MNIST, normalize it, define a small MLP, and run a quick\n",
    "sanity check forward pass to verify shapes before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2abd96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:39.997115Z",
     "iopub.status.busy": "2025-09-05T09:20:39.996938Z",
     "iopub.status.idle": "2025-09-05T09:20:40.000108Z",
     "shell.execute_reply": "2025-09-05T09:20:39.999425Z"
    },
    "papermill": {
     "duration": 0.007733,
     "end_time": "2025-09-05T09:20:40.001234",
     "exception": false,
     "start_time": "2025-09-05T09:20:39.993501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: only run this if your torch/torchvision install is broken.\n",
    "# For GPU on Kaggle (CUDA 12.1 wheels):\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# For CPU-only:\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dc40f",
   "metadata": {
    "papermill": {
     "duration": 0.002715,
     "end_time": "2025-09-05T09:20:40.006922",
     "exception": false,
     "start_time": "2025-09-05T09:20:40.004207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports & device\n",
    "\n",
    "We’ll autodetect CUDA and fall back to CPU. The code works either way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ae29f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:40.013341Z",
     "iopub.status.busy": "2025-09-05T09:20:40.013156Z",
     "iopub.status.idle": "2025-09-05T09:20:49.847493Z",
     "shell.execute_reply": "2025-09-05T09:20:49.846658Z"
    },
    "papermill": {
     "duration": 9.839019,
     "end_time": "2025-09-05T09:20:49.848802",
     "exception": false,
     "start_time": "2025-09-05T09:20:40.009783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "torchvision: 0.21.0+cu124\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bea211",
   "metadata": {
    "papermill": {
     "duration": 0.002916,
     "end_time": "2025-09-05T09:20:49.855060",
     "exception": false,
     "start_time": "2025-09-05T09:20:49.852144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset & transforms\n",
    "\n",
    "- `ToTensor()` → scales pixels to [0,1] with shape [1, 28, 28].\n",
    "- `Normalize((0.1307,), (0.3081,))` → center/scale using MNIST stats.\n",
    "  (Note the commas: single-element tuples.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a0bf5",
   "metadata": {
    "papermill": {
     "duration": 0.00288,
     "end_time": "2025-09-05T09:20:49.860874",
     "exception": false,
     "start_time": "2025-09-05T09:20:49.857994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we normalize MNIST with `(0.1307,), (0.3081,)`?\n",
    "\n",
    "After `ToTensor()`, MNIST images are scaled to `[0,1]`, but their distribution isn’t centered and doesn’t have unit variance:\n",
    "- Mean pixel value is about **0.1307** (most pixels are dark background).\n",
    "- Standard deviation is about **0.3081**.\n",
    "\n",
    "**Why normalize?**\n",
    "- Centering (subtracting the mean) makes neuron inputs hover around zero, which helps gradients flow and speeds up learning.\n",
    "- Scaling (dividing by the std) puts features on a comparable scale, making optimization more stable and less sensitive to learning rates.\n",
    "\n",
    "**Why those exact numbers?**\n",
    "- They are the empirical mean and std of the MNIST training set computed over all pixels.\n",
    "- Using dataset-specific stats is better than generic choices (like 0.5/0.5) because it matches the true data distribution.\n",
    "\n",
    "**Why the tuples — and why the comma is so important?**\n",
    "- `Normalize` expects a *sequence* (list or tuple) with one value per channel.\n",
    "- MNIST has 1 channel → we need one mean and one std → a 1-element tuple.\n",
    "- In Python:\n",
    "  - `(0.3081,)` → a tuple containing one float ✅\n",
    "  - `(0.3081)` → just a float ❌\n",
    "- If you forget the comma, you pass a float instead of a tuple. That breaks the shape handling inside `Normalize` and can lead to confusing errors (like “std evaluated to zero”).\n",
    "\n",
    "**What if we skip normalization?**\n",
    "- The model may still learn (MNIST is simple), but:\n",
    "  - Training is slower.\n",
    "  - Optimization is less stable.\n",
    "  - Accuracy may plateau lower.\n",
    "- For harder datasets (like CIFAR or ImageNet), skipping normalization can mean the model fails to learn at all.\n",
    "\n",
    "**TL;DR**\n",
    "Normalization with `(0.1307,), (0.3081,)` standardizes MNIST inputs to zero-like mean and unit-like variance.  \n",
    "The trailing comma is crucial because it makes those values tuples, not plain floats, which is exactly what `Normalize` expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8010d065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:49.867661Z",
     "iopub.status.busy": "2025-09-05T09:20:49.867336Z",
     "iopub.status.idle": "2025-09-05T09:20:53.686104Z",
     "shell.execute_reply": "2025-09-05T09:20:53.685306Z"
    },
    "papermill": {
     "duration": 3.823525,
     "end_time": "2025-09-05T09:20:53.687305",
     "exception": false,
     "start_time": "2025-09-05T09:20:49.863780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.46MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.53MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one sample: torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "x0, y0 = train_mnist[0]\n",
    "print(\"one sample:\", x0.shape, y0)  # torch.Size([1, 28, 28]) label_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f5003",
   "metadata": {
    "papermill": {
     "duration": 0.003555,
     "end_time": "2025-09-05T09:20:53.695750",
     "exception": false,
     "start_time": "2025-09-05T09:20:53.692195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "A simple fully-connected classifier:\n",
    "- Flatten 28×28 → 784\n",
    "- Hidden: 300 → 300 with LeakyReLU\n",
    "- Output: 10 logits (no Softmax; CrossEntropyLoss expects logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acd606a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:53.703851Z",
     "iopub.status.busy": "2025-09-05T09:20:53.703620Z",
     "iopub.status.idle": "2025-09-05T09:20:53.711824Z",
     "shell.execute_reply": "2025-09-05T09:20:53.711241Z"
    },
    "papermill": {
     "duration": 0.01354,
     "end_time": "2025-09-05T09:20:53.712861",
     "exception": false,
     "start_time": "2025-09-05T09:20:53.699321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# In PyTorch, p.numel() returns the number of elements (scalars) in the tensor p.\n",
    "\n",
    "p = torch.randn(3, 4)   # shape [3,4]\n",
    "print(p.numel())        # 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a051784a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:53.720864Z",
     "iopub.status.busy": "2025-09-05T09:20:53.720663Z",
     "iopub.status.idle": "2025-09-05T09:20:53.928902Z",
     "shell.execute_reply": "2025-09-05T09:20:53.928072Z"
    },
    "papermill": {
     "duration": 0.21364,
     "end_time": "2025-09-05T09:20:53.930138",
     "exception": false,
     "start_time": "2025-09-05T09:20:53.716498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 328810\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 10)  # logits\n",
    ").to(device)\n",
    "\n",
    "sum_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"model params:\", sum_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ae044",
   "metadata": {
    "papermill": {
     "duration": 0.003604,
     "end_time": "2025-09-05T09:20:53.937765",
     "exception": false,
     "start_time": "2025-09-05T09:20:53.934161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check (single example)\n",
    "\n",
    "Flatten to 784 features, forward once, confirm output shape [1, 10].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ddeb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:53.945895Z",
     "iopub.status.busy": "2025-09-05T09:20:53.945670Z",
     "iopub.status.idle": "2025-09-05T09:20:54.098564Z",
     "shell.execute_reply": "2025-09-05T09:20:54.097817Z"
    },
    "papermill": {
     "duration": 0.158368,
     "end_time": "2025-09-05T09:20:54.099796",
     "exception": false,
     "start_time": "2025-09-05T09:20:53.941428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single forward shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "digit, cls = train_mnist[0]\n",
    "digit = digit.to(device).view(1, 28*28)  # add batch dim = 1\n",
    "with torch.no_grad():\n",
    "    out = model(digit)\n",
    "print(\"single forward shape:\", out.shape)  # torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bbeed",
   "metadata": {
    "papermill": {
     "duration": 0.003797,
     "end_time": "2025-09-05T09:20:54.107612",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.103815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check with dataset loop (first item only)\n",
    "\n",
    "Iterate the dataset, move to device, flatten, run model, print shape, break.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93c39c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:54.116163Z",
     "iopub.status.busy": "2025-09-05T09:20:54.115927Z",
     "iopub.status.idle": "2025-09-05T09:20:54.121353Z",
     "shell.execute_reply": "2025-09-05T09:20:54.120768Z"
    },
    "papermill": {
     "duration": 0.011008,
     "end_time": "2025-09-05T09:20:54.122359",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.111351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for digit, cls in train_mnist:\n",
    "    digit = digit.to(device)\n",
    "    digit = digit.view(digit.shape[0], 28*28)\n",
    "    with torch.no_grad():\n",
    "        print(model(digit).shape)  # expected: torch.Size([1, 10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b3d31",
   "metadata": {
    "papermill": {
     "duration": 0.003729,
     "end_time": "2025-09-05T09:20:54.129927",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.126198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `digit.view(digit.shape[0], 28*28)`?\n",
    "\n",
    "Each MNIST image comes as a tensor of shape `[B, 1, 28, 28]`:\n",
    "- `B` = batch size  \n",
    "- `1` = number of channels (grayscale)  \n",
    "- `28 × 28` = image height and width  \n",
    "\n",
    "Our model starts with a `Linear(28*28, 300)` layer, which expects a\n",
    "**flat vector of 784 features per image**, not a 2D grid.\n",
    "\n",
    "The call\n",
    "\n",
    "``` python\n",
    "digit = digit.view(digit.shape[0], 28*28)\n",
    "```\n",
    "\n",
    "does two things:\n",
    "1. Keeps the batch dimension (`digit.shape[0]`).\n",
    "2. Flattens each `[1,28,28]` image into a single vector `[784]`.\n",
    "\n",
    "So:\n",
    "- Before: `[B, 1, 28, 28]`  \n",
    "- After:  `[B, 784]`  \n",
    "\n",
    "This reshaping step bridges the gap between image-shaped data and the\n",
    "fully connected (dense) layers of our MLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da8364",
   "metadata": {
    "papermill": {
     "duration": 0.003651,
     "end_time": "2025-09-05T09:20:54.137594",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.133943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloaders\n",
    "\n",
    "We’ll iterate in mini-batches for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c161fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:54.145963Z",
     "iopub.status.busy": "2025-09-05T09:20:54.145760Z",
     "iopub.status.idle": "2025-09-05T09:20:54.151637Z",
     "shell.execute_reply": "2025-09-05T09:20:54.151124Z"
    },
    "papermill": {
     "duration": 0.011231,
     "end_time": "2025-09-05T09:20:54.152648",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.141417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 162)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "batch_size = 62 \n",
    "train_dl = DataLoader(\n",
    "    train_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2, \n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29372d1c",
   "metadata": {
    "papermill": {
     "duration": 0.003839,
     "end_time": "2025-09-05T09:20:54.160481",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.156642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding `DataLoader` arguments\n",
    "\n",
    "When we wrap our MNIST datasets in `DataLoader`, we specify a few\n",
    "important options:\n",
    "\n",
    "- **`batch_size=64`**  \n",
    "  - How many samples to group together in one batch.  \n",
    "  - Instead of returning a single `[1, 28, 28]` image, the loader\n",
    "    returns `[64, 1, 28, 28]` tensors.  \n",
    "  - Larger batch sizes improve GPU utilization and give smoother\n",
    "    gradient estimates, but also use more memory.  \n",
    "  - On CPU, smaller batches can be more practical to keep things fast\n",
    "    and memory-efficient.\n",
    "\n",
    "- **`shuffle=True` (for training)**  \n",
    "  - Each epoch, the training data is shuffled.  \n",
    "  - Prevents the model from simply memorizing the order of the data.  \n",
    "  - Helps generalization because each mini-batch looks different each\n",
    "    epoch.  \n",
    "  - For evaluation (`test_dl`), we use `shuffle=False` so results are\n",
    "    deterministic and ordered.\n",
    "\n",
    "- **`num_workers=2`**  \n",
    "  - Number of subprocesses used to load data in parallel.  \n",
    "  - `0` means load in the main process (slower).  \n",
    "  - On CPU or GPU, having a few workers (like 2–4) allows data to be\n",
    "    prefetched while the model is training on the previous batch,\n",
    "    keeping the pipeline efficient.  \n",
    "  - On Kaggle, small values (like 2) are often safe.\n",
    "\n",
    "- **`pin_memory=(device==\"cuda\")`**  \n",
    "  - *Pinned (page-locked) memory* speeds up data transfer from CPU RAM\n",
    "    to GPU memory.  \n",
    "  - If `device==\"cuda\"`, we set `pin_memory=True` so each batch can be\n",
    "    moved to GPU more efficiently with `.to(\"cuda\")`.  \n",
    "  - If `device==\"cpu\"`, this option does nothing and can safely remain\n",
    "    `False`.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "- Training loader: `batch_size=64`, `shuffle=True`  \n",
    "- Test loader: `batch_size=64`, `shuffle=False`  \n",
    "- Use a few `num_workers` to overlap data loading with computation.  \n",
    "- Enable `pin_memory` only when training on CUDA for faster CPU→GPU\n",
    "  transfers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008983a2",
   "metadata": {
    "papermill": {
     "duration": 0.003731,
     "end_time": "2025-09-05T09:20:54.168069",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.164338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss & Optimizer\n",
    "\n",
    "- **Loss:** `CrossEntropyLoss` compares the model’s **logits** to the\n",
    "  ground-truth class indices. It internally applies `log_softmax`, so\n",
    "  we **do not** put a `Softmax` layer in the model.\n",
    "- **Optimizer:** `Adam` with a standard learning rate (1e-3) works well\n",
    "  for this small MLP. It adapts per-parameter step sizes and usually\n",
    "  converges faster than plain SGD.\n",
    "- **Seed:** we set a manual seed for reproducibility (weight init and\n",
    "  the Adam state).\n",
    "- This works the same on **CPU or CUDA**; no device-specific changes are\n",
    "  needed for defining the loss/optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a107d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T09:20:54.176480Z",
     "iopub.status.busy": "2025-09-05T09:20:54.176266Z",
     "iopub.status.idle": "2025-09-05T09:20:54.185032Z",
     "shell.execute_reply": "2025-09-05T09:20:54.184357Z"
    },
    "papermill": {
     "duration": 0.014122,
     "end_time": "2025-09-05T09:20:54.186000",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.171878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(loss_fn)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd8fcf",
   "metadata": {
    "papermill": {
     "duration": 0.003774,
     "end_time": "2025-09-05T09:20:54.193933",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.190159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d0bb9",
   "metadata": {
    "papermill": {
     "duration": 0.003776,
     "end_time": "2025-09-05T09:20:54.201629",
     "exception": false,
     "start_time": "2025-09-05T09:20:54.197853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.144737,
   "end_time": "2025-09-05T09:20:55.624368",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T09:20:35.479631",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
