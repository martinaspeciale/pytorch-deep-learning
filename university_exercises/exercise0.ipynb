{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f31077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:34.137558Z",
     "iopub.status.busy": "2025-09-05T11:00:34.137228Z",
     "iopub.status.idle": "2025-09-05T11:00:34.142298Z",
     "shell.execute_reply": "2025-09-05T11:00:34.141401Z"
    },
    "papermill": {
     "duration": 0.014648,
     "end_time": "2025-09-05T11:00:34.144187",
     "exception": false,
     "start_time": "2025-09-05T11:00:34.129539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d61baa",
   "metadata": {
    "papermill": {
     "duration": 0.007108,
     "end_time": "2025-09-05T11:00:34.158196",
     "exception": false,
     "start_time": "2025-09-05T11:00:34.151088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST — MLP warm-up\n",
    "\n",
    "We’ll load MNIST, normalize it, define a small MLP, and run a quick\n",
    "sanity check forward pass to verify shapes before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db3f19e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:34.173168Z",
     "iopub.status.busy": "2025-09-05T11:00:34.172713Z",
     "iopub.status.idle": "2025-09-05T11:00:34.177815Z",
     "shell.execute_reply": "2025-09-05T11:00:34.176861Z"
    },
    "papermill": {
     "duration": 0.014758,
     "end_time": "2025-09-05T11:00:34.179635",
     "exception": false,
     "start_time": "2025-09-05T11:00:34.164877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: only run this if your torch/torchvision install is broken.\n",
    "# For GPU on Kaggle (CUDA 12.1 wheels):\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# For CPU-only:\n",
    "# !pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a114f6",
   "metadata": {
    "papermill": {
     "duration": 0.008246,
     "end_time": "2025-09-05T11:00:34.195488",
     "exception": false,
     "start_time": "2025-09-05T11:00:34.187242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports & device\n",
    "\n",
    "We’ll autodetect CUDA and fall back to CPU. The code works either way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f371326c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:34.208905Z",
     "iopub.status.busy": "2025-09-05T11:00:34.208001Z",
     "iopub.status.idle": "2025-09-05T11:00:44.909391Z",
     "shell.execute_reply": "2025-09-05T11:00:44.908254Z"
    },
    "papermill": {
     "duration": 10.709742,
     "end_time": "2025-09-05T11:00:44.911088",
     "exception": false,
     "start_time": "2025-09-05T11:00:34.201346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "torchvision: 0.21.0+cu124\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71315e8b",
   "metadata": {
    "papermill": {
     "duration": 0.005171,
     "end_time": "2025-09-05T11:00:44.921794",
     "exception": false,
     "start_time": "2025-09-05T11:00:44.916623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset & transforms\n",
    "\n",
    "- `ToTensor()` → scales pixels to [0,1] with shape [1, 28, 28].\n",
    "- `Normalize((0.1307,), (0.3081,))` → center/scale using MNIST stats.\n",
    "  (Note the commas: single-element tuples.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b897a5",
   "metadata": {
    "papermill": {
     "duration": 0.005015,
     "end_time": "2025-09-05T11:00:44.932076",
     "exception": false,
     "start_time": "2025-09-05T11:00:44.927061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we normalize MNIST with `(0.1307,), (0.3081,)`?\n",
    "\n",
    "After `ToTensor()`, MNIST images are scaled to `[0,1]`, but their distribution isn’t centered and doesn’t have unit variance:\n",
    "- Mean pixel value is about **0.1307** (most pixels are dark background).\n",
    "- Standard deviation is about **0.3081**.\n",
    "\n",
    "**Why normalize?**\n",
    "- Centering (subtracting the mean) makes neuron inputs hover around zero, which helps gradients flow and speeds up learning.\n",
    "- Scaling (dividing by the std) puts features on a comparable scale, making optimization more stable and less sensitive to learning rates.\n",
    "\n",
    "**Why those exact numbers?**\n",
    "- They are the empirical mean and std of the MNIST training set computed over all pixels.\n",
    "- Using dataset-specific stats is better than generic choices (like 0.5/0.5) because it matches the true data distribution.\n",
    "\n",
    "**Why the tuples — and why the comma is so important?**\n",
    "- `Normalize` expects a *sequence* (list or tuple) with one value per channel.\n",
    "- MNIST has 1 channel → we need one mean and one std → a 1-element tuple.\n",
    "- In Python:\n",
    "  - `(0.3081,)` → a tuple containing one float ✅\n",
    "  - `(0.3081)` → just a float ❌\n",
    "- If you forget the comma, you pass a float instead of a tuple. That breaks the shape handling inside `Normalize` and can lead to confusing errors (like “std evaluated to zero”).\n",
    "\n",
    "**What if we skip normalization?**\n",
    "- The model may still learn (MNIST is simple), but:\n",
    "  - Training is slower.\n",
    "  - Optimization is less stable.\n",
    "  - Accuracy may plateau lower.\n",
    "- For harder datasets (like CIFAR or ImageNet), skipping normalization can mean the model fails to learn at all.\n",
    "\n",
    "**TL;DR**\n",
    "Normalization with `(0.1307,), (0.3081,)` standardizes MNIST inputs to zero-like mean and unit-like variance.  \n",
    "The trailing comma is crucial because it makes those values tuples, not plain floats, which is exactly what `Normalize` expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a18c923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:44.945321Z",
     "iopub.status.busy": "2025-09-05T11:00:44.944444Z",
     "iopub.status.idle": "2025-09-05T11:00:49.114210Z",
     "shell.execute_reply": "2025-09-05T11:00:49.113213Z"
    },
    "papermill": {
     "duration": 4.177489,
     "end_time": "2025-09-05T11:00:49.115684",
     "exception": false,
     "start_time": "2025-09-05T11:00:44.938195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.21MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one sample: torch.Size([1, 28, 28]) 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "x0, y0 = train_mnist[0]\n",
    "print(\"one sample:\", x0.shape, y0)  # torch.Size([1, 28, 28]) label_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52026e77",
   "metadata": {
    "papermill": {
     "duration": 0.006065,
     "end_time": "2025-09-05T11:00:49.128413",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.122348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "A simple fully-connected classifier:\n",
    "- Flatten 28×28 → 784\n",
    "- Hidden: 300 → 300 with LeakyReLU\n",
    "- Output: 10 logits (no Softmax; CrossEntropyLoss expects logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed716756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.142701Z",
     "iopub.status.busy": "2025-09-05T11:00:49.141977Z",
     "iopub.status.idle": "2025-09-05T11:00:49.151515Z",
     "shell.execute_reply": "2025-09-05T11:00:49.150131Z"
    },
    "papermill": {
     "duration": 0.0185,
     "end_time": "2025-09-05T11:00:49.153184",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.134684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# In PyTorch, p.numel() returns the number of elements (scalars) in the tensor p.\n",
    "\n",
    "p = torch.randn(3, 4)   # shape [3,4]\n",
    "print(p.numel())        # 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a27a50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.167936Z",
     "iopub.status.busy": "2025-09-05T11:00:49.167232Z",
     "iopub.status.idle": "2025-09-05T11:00:49.179633Z",
     "shell.execute_reply": "2025-09-05T11:00:49.178561Z"
    },
    "papermill": {
     "duration": 0.021764,
     "end_time": "2025-09-05T11:00:49.181455",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.159691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 328810\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 300),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(300, 10)  # logits\n",
    ").to(device)\n",
    "\n",
    "sum_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"model params:\", sum_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cdb13",
   "metadata": {
    "papermill": {
     "duration": 0.006402,
     "end_time": "2025-09-05T11:00:49.194658",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.188256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check (single example)\n",
    "\n",
    "Flatten to 784 features, forward once, confirm output shape [1, 10].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dfb0fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.208886Z",
     "iopub.status.busy": "2025-09-05T11:00:49.208564Z",
     "iopub.status.idle": "2025-09-05T11:00:49.224525Z",
     "shell.execute_reply": "2025-09-05T11:00:49.223576Z"
    },
    "papermill": {
     "duration": 0.024828,
     "end_time": "2025-09-05T11:00:49.226054",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.201226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single forward shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "digit, cls = train_mnist[0]\n",
    "digit = digit.to(device).view(1, 28*28)  # add batch dim = 1\n",
    "with torch.no_grad():\n",
    "    out = model(digit)\n",
    "print(\"single forward shape:\", out.shape)  # torch.Size([1, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3974e48",
   "metadata": {
    "papermill": {
     "duration": 0.006968,
     "end_time": "2025-09-05T11:00:49.241766",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.234798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity check with dataset loop (first item only)\n",
    "\n",
    "Iterate the dataset, move to device, flatten, run model, print shape, break.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e72e441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.256650Z",
     "iopub.status.busy": "2025-09-05T11:00:49.255804Z",
     "iopub.status.idle": "2025-09-05T11:00:49.263110Z",
     "shell.execute_reply": "2025-09-05T11:00:49.262078Z"
    },
    "papermill": {
     "duration": 0.01619,
     "end_time": "2025-09-05T11:00:49.264568",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.248378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for digit, cls in train_mnist:\n",
    "    digit = digit.to(device)\n",
    "    digit = digit.view(digit.shape[0], 28*28)\n",
    "    with torch.no_grad():\n",
    "        print(model(digit).shape)  # expected: torch.Size([1, 10])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0de7e8",
   "metadata": {
    "papermill": {
     "duration": 0.006206,
     "end_time": "2025-09-05T11:00:49.277473",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.271267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `digit.view(digit.shape[0], 28*28)`?\n",
    "\n",
    "Each MNIST image comes as a tensor of shape `[B, 1, 28, 28]`:\n",
    "- `B` = batch size  \n",
    "- `1` = number of channels (grayscale)  \n",
    "- `28 × 28` = image height and width  \n",
    "\n",
    "Our model starts with a `Linear(28*28, 300)` layer, which expects a\n",
    "**flat vector of 784 features per image**, not a 2D grid.\n",
    "\n",
    "The call\n",
    "\n",
    "``` python\n",
    "digit = digit.view(digit.shape[0], 28*28)\n",
    "```\n",
    "\n",
    "does two things:\n",
    "1. Keeps the batch dimension (`digit.shape[0]`).\n",
    "2. Flattens each `[1,28,28]` image into a single vector `[784]`.\n",
    "\n",
    "So:\n",
    "- Before: `[B, 1, 28, 28]`  \n",
    "- After:  `[B, 784]`  \n",
    "\n",
    "This reshaping step bridges the gap between image-shaped data and the\n",
    "fully connected (dense) layers of our MLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a123187",
   "metadata": {
    "papermill": {
     "duration": 0.006208,
     "end_time": "2025-09-05T11:00:49.290074",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.283866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloaders\n",
    "\n",
    "We’ll iterate in mini-batches for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f10543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.304232Z",
     "iopub.status.busy": "2025-09-05T11:00:49.303930Z",
     "iopub.status.idle": "2025-09-05T11:00:49.313991Z",
     "shell.execute_reply": "2025-09-05T11:00:49.313039Z"
    },
    "papermill": {
     "duration": 0.01887,
     "end_time": "2025-09-05T11:00:49.315509",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.296639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 162)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "batch_size = 62 \n",
    "train_dl = DataLoader(\n",
    "    train_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2, \n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_mnist, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=(device==\"cuda\")\n",
    ")\n",
    "\n",
    "len(train_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bbcfc",
   "metadata": {
    "papermill": {
     "duration": 0.006406,
     "end_time": "2025-09-05T11:00:49.328806",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.322400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Understanding `DataLoader` arguments\n",
    "\n",
    "When we wrap our MNIST datasets in `DataLoader`, we specify a few\n",
    "important options:\n",
    "\n",
    "- **`batch_size=64`**  \n",
    "  - How many samples to group together in one batch.  \n",
    "  - Instead of returning a single `[1, 28, 28]` image, the loader\n",
    "    returns `[64, 1, 28, 28]` tensors.  \n",
    "  - Larger batch sizes improve GPU utilization and give smoother\n",
    "    gradient estimates, but also use more memory.  \n",
    "  - On CPU, smaller batches can be more practical to keep things fast\n",
    "    and memory-efficient.\n",
    "\n",
    "- **`shuffle=True` (for training)**  \n",
    "  - Each epoch, the training data is shuffled.  \n",
    "  - Prevents the model from simply memorizing the order of the data.  \n",
    "  - Helps generalization because each mini-batch looks different each\n",
    "    epoch.  \n",
    "  - For evaluation (`test_dl`), we use `shuffle=False` so results are\n",
    "    deterministic and ordered.\n",
    "\n",
    "- **`num_workers=2`**  \n",
    "  - Number of subprocesses used to load data in parallel.  \n",
    "  - `0` means load in the main process (slower).  \n",
    "  - On CPU or GPU, having a few workers (like 2–4) allows data to be\n",
    "    prefetched while the model is training on the previous batch,\n",
    "    keeping the pipeline efficient.  \n",
    "  - On Kaggle, small values (like 2) are often safe.\n",
    "\n",
    "- **`pin_memory=(device==\"cuda\")`**  \n",
    "  - *Pinned (page-locked) memory* speeds up data transfer from CPU RAM\n",
    "    to GPU memory.  \n",
    "  - If `device==\"cuda\"`, we set `pin_memory=True` so each batch can be\n",
    "    moved to GPU more efficiently with `.to(\"cuda\")`.  \n",
    "  - If `device==\"cpu\"`, this option does nothing and can safely remain\n",
    "    `False`.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "- Training loader: `batch_size=64`, `shuffle=True`  \n",
    "- Test loader: `batch_size=64`, `shuffle=False`  \n",
    "- Use a few `num_workers` to overlap data loading with computation.  \n",
    "- Enable `pin_memory` only when training on CUDA for faster CPU→GPU\n",
    "  transfers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67041eea",
   "metadata": {
    "papermill": {
     "duration": 0.006385,
     "end_time": "2025-09-05T11:00:49.341671",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.335286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss & Optimizer\n",
    "\n",
    "- **Loss:** `CrossEntropyLoss` compares the model’s **logits** to the\n",
    "  ground-truth class indices. It internally applies `log_softmax`, so\n",
    "  we **do not** put a `Softmax` layer in the model.\n",
    "- **Optimizer:** `Adam` with a standard learning rate (1e-3) works well\n",
    "  for this small MLP. It adapts per-parameter step sizes and usually\n",
    "  converges faster than plain SGD.\n",
    "- **Seed:** we set a manual seed for reproducibility (weight init and\n",
    "  the Adam state).\n",
    "- This works the same on **CPU or CUDA**; no device-specific changes are\n",
    "  needed for defining the loss/optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca45f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.357229Z",
     "iopub.status.busy": "2025-09-05T11:00:49.356365Z",
     "iopub.status.idle": "2025-09-05T11:00:49.368682Z",
     "shell.execute_reply": "2025-09-05T11:00:49.367710Z"
    },
    "papermill": {
     "duration": 0.022074,
     "end_time": "2025-09-05T11:00:49.370229",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.348155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(loss_fn)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f638e62",
   "metadata": {
    "papermill": {
     "duration": 0.00661,
     "end_time": "2025-09-05T11:00:49.383828",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.377218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Loop \n",
    "We train for a few epochs using mini-batches:\n",
    "- Switch the model to `train()` mode (enables layers like dropout/batchnorm if present)\n",
    "- Move each batch to the selected `device` (CPU or CUDA)\n",
    "- **Flatten** `[B, 1, 28, 28] → [B, 784]` before the first linear layer.\n",
    "- Forward → compute **CrossEntropyLoss** on logits → backprop → optimizer step.\n",
    "- Track running loss and accuracy for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49d572",
   "metadata": {
    "papermill": {
     "duration": 0.006541,
     "end_time": "2025-09-05T11:00:49.396956",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.390415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. `train_dl`\n",
    "   * this is a DataLoader we created from train_mnist\n",
    "   * each iteration returns a mini-batch of samples\n",
    "   * by default, it yields a tuple: `(batch_of_images, batch_of_labels)`\n",
    "3. `tqdm(train_dl, desc= ...)`\n",
    "   * `tqdm` wraps the DataLoader so we get a live progress bar while looping\n",
    "   * the desc string is shown at the start of the bar \n",
    "5. `for x, y in bar:`\n",
    "   * on each loop:\n",
    "        - `x` = a batch of images, shape [B,1,28,28]\n",
    "        - `y` = the corresponding batch of labels, shape [B] (each entry is an integer 0-9 for the digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16568a11",
   "metadata": {
    "papermill": {
     "duration": 0.006285,
     "end_time": "2025-09-05T11:00:49.409829",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.403544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we flatten `x` but not `y`?\n",
    "\n",
    "- **`x` (the images)**  \n",
    "  - Each batch arrives from the `DataLoader` with shape `[B, 1, 28, 28]`  \n",
    "    (`B` = batch size, `1` = grayscale channel, `28×28` = pixels).  \n",
    "  - Our model begins with a linear layer `Linear(28*28, 300)`, which\n",
    "    expects a **2D tensor** of shape `[B, 784]`.  \n",
    "  - Therefore, we flatten each image with  \n",
    "    `x = x.view(B, 28*28)` so every image becomes a 784-dimensional\n",
    "    vector, while preserving the batch dimension.\n",
    "\n",
    "- **`y` (the labels)**  \n",
    "  - Labels are already a 1D tensor of integers with shape `[B]`\n",
    "    (e.g. `[5, 0, 4, 1, 9, ...]`).  \n",
    "  - `CrossEntropyLoss` expects predictions as `[B, num_classes]`\n",
    "    (logits) and targets as `[B]` (integer class indices).  \n",
    "  - Since `y` is already in the right format, we **don’t reshape it**.\n",
    "\n",
    "**In short:**  \n",
    "- Flatten `x` because the network needs flat input vectors.  \n",
    "- Leave `y` as is because it already contains class indices in the\n",
    "expected shape for the loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516b89e",
   "metadata": {
    "papermill": {
     "duration": 0.006353,
     "end_time": "2025-09-05T11:00:49.422962",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.416609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tracking metrics during training\n",
    "\n",
    "Inside the training loop we compute and accumulate statistics so that we\n",
    "can monitor progress:\n",
    "\n",
    "- **`running_loss += loss.item() * x.size(0)`**  \n",
    "  - `loss.item()` gives the scalar loss value for the current batch.  \n",
    "  - We multiply by `x.size(0)` (the batch size) so that when we sum over\n",
    "    all batches, each sample contributes equally.  \n",
    "  - At the end of the epoch, dividing by `total` gives the **average\n",
    "    loss per sample**.\n",
    "\n",
    "- **`preds = logits.argmax(dim=1)`**  \n",
    "  - From the model’s output `[B, 10]` (logits), we take the index of the\n",
    "    maximum value along `dim=1` for each sample.  \n",
    "  - This gives the predicted digit class for each image.\n",
    "\n",
    "- **`correct += (preds == y).sum().item()`**  \n",
    "  - Compares predictions to ground-truth labels `y`.  \n",
    "  - Counts how many were correct in this batch, adds to the running\n",
    "    total.\n",
    "\n",
    "- **`total += y.numel()`**  \n",
    "  - Increments by the number of samples in this batch.  \n",
    "  - Used to compute overall averages.\n",
    "\n",
    "- **`bar.set_postfix(...)`**  \n",
    "  - Updates the live `tqdm` progress bar with the current batch loss and\n",
    "    accuracy (`correct / total`).\n",
    "\n",
    "After the loop:\n",
    "\n",
    "- **`epoch_loss = running_loss / total`**  \n",
    "  - Average loss per sample across the entire epoch.\n",
    "\n",
    "- **`epoch_acc = correct / total`**  \n",
    "  - Fraction of correctly classified samples across the entire epoch.\n",
    "\n",
    "- **`print(...)`**  \n",
    "  - Logs a summary line showing the final loss and accuracy for this\n",
    "    epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e39ed",
   "metadata": {
    "papermill": {
     "duration": 0.006548,
     "end_time": "2025-09-05T11:00:49.436097",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.429549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `argmax(dim=1)`?\n",
    "\n",
    "The model outputs logits of shape `[B, 10]`:\n",
    "- `B` = batch size  \n",
    "- `10` = number of classes (digits 0–9 for MNIST)  \n",
    "\n",
    "Each **row** corresponds to one sample, and each **column** corresponds\n",
    "to the score for a particular class.\n",
    "\n",
    "Example for a batch of size 4:\n",
    "\n",
    "    logits =\n",
    "    [[-1.2,  0.3,  2.1, ..., -0.7],   # sample 1\n",
    "     [ 0.5, -0.2,  0.1, ..., -1.3],   # sample 2\n",
    "     [ 2.9,  1.2, -0.4, ...,  0.0],   # sample 3\n",
    "     [ 0.1,  0.4,  0.2, ..., -0.6]]   # sample 4\n",
    "\n",
    "- If we used `argmax(dim=0)`, we would be taking the maximum **down the\n",
    "  batch** for each class column. That compares different samples to each\n",
    "  other, which is not meaningful for classification.\n",
    "\n",
    "- If we use `argmax(dim=1)`, we take the maximum **across the 10 class\n",
    "  scores** for each row (sample). That selects the predicted class for\n",
    "  each sample independently.\n",
    "\n",
    "So:\n",
    "\n",
    "    preds = logits.argmax(dim=1)\n",
    "\n",
    "returns a vector of shape `[B]` with one integer (0–9) per sample, e.g.:\n",
    "\n",
    "    tensor([2, 0, 0, 1])   # predicted classes for 4 samples\n",
    "\n",
    "**Summary:**  \n",
    "We use `dim=1` because that dimension represents the class scores.\n",
    "Choosing the max along `dim=1` gives the most likely class **for each\n",
    "sample in the batch**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5490c7",
   "metadata": {
    "papermill": {
     "duration": 0.006351,
     "end_time": "2025-09-05T11:00:49.449049",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.442698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `.item()`?\n",
    "\n",
    "In the training loop we update the counter of correct predictions:\n",
    "\n",
    "    correct += (preds == y).sum().item()\n",
    "\n",
    "Step by step:\n",
    "\n",
    "1. **`preds == y`**  \n",
    "   Compares predicted labels with true labels, giving a Boolean tensor of\n",
    "   shape `[B]` (e.g. `[True, False, True, ...]`).\n",
    "\n",
    "2. **`.sum()`**  \n",
    "   Sums over the batch, counting how many predictions were correct.  \n",
    "   The result is a **0-dimensional PyTorch tensor**, e.g. `tensor(48)`.\n",
    "\n",
    "3. **`.item()`**  \n",
    "   Extracts the scalar value from the tensor and converts it into a plain\n",
    "   Python number (`int` or `float`).  \n",
    "   This is needed because `correct` is just a Python integer, and adding\n",
    "   a tensor directly would cause a type mismatch.\n",
    "\n",
    "4. **`correct += ...`**  \n",
    "   Accumulates the number of correct predictions from each batch into a\n",
    "   running total.\n",
    "\n",
    "**Summary:**  \n",
    "We use `.item()` to safely convert a scalar PyTorch tensor into a Python\n",
    "number so it can be added to the counter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42759932",
   "metadata": {
    "papermill": {
     "duration": 0.006491,
     "end_time": "2025-09-05T11:00:49.462131",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.455640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why multiply by `x.size(0)` instead of dividing by batches?\n",
    "\n",
    "In the training loop we accumulate loss like this:\n",
    "\n",
    "    running_loss += loss.item() * x.size(0)\n",
    "    ...\n",
    "    epoch_loss = running_loss / total\n",
    "\n",
    "- **`loss.item()`** is already the **average loss per sample** in the\n",
    "  current batch (that is how `CrossEntropyLoss` behaves by default).\n",
    "- Multiplying by `x.size(0)` (the batch size) converts it into the\n",
    "  **total loss for that batch**.\n",
    "- Summing across all batches and then dividing by the **total number of\n",
    "  samples** gives the true mean loss per sample across the entire epoch.\n",
    "\n",
    "Why not just average the batch means?\n",
    "\n",
    "- If we simply did `(sum(losses) / num_batches)`, every batch would be\n",
    "  weighted equally.\n",
    "- This becomes incorrect if the **last batch is smaller** than the rest\n",
    "  (common when dataset size is not divisible by batch size).\n",
    "- In that case, the smaller batch would count just as much as a full\n",
    "  batch, skewing the average.\n",
    "\n",
    "**Summary:**  \n",
    "By multiplying with `x.size(0)` and dividing by the total number of\n",
    "samples, we ensure that **every sample contributes equally** to the\n",
    "epoch loss, regardless of batch size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b22a64",
   "metadata": {
    "papermill": {
     "duration": 0.006464,
     "end_time": "2025-09-05T11:00:49.475135",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.468671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Why do we use `bar.set_postfix(...)`?\n",
    "\n",
    "We wrapped the training loop with `tqdm` to get a progress bar:\n",
    "\n",
    "    bar = tqdm(train_dl, desc=f\"Epoch {epoch}/{epochs}\")\n",
    "\n",
    "The method `bar.set_postfix(...)` lets us show **live metrics** next to\n",
    "the progress bar during training. In this case:\n",
    "\n",
    "- **`loss=loss.item()`**  \n",
    "  Displays the most recent batch’s loss (a scalar).  \n",
    "  This gives a quick view of how the current batch is doing.\n",
    "\n",
    "- **`acc=(correct / total)`**  \n",
    "  Shows the running accuracy across all samples seen so far in this\n",
    "  epoch.  \n",
    "  It is updated continuously as more batches are processed.\n",
    "\n",
    "**Why it’s useful:**  \n",
    "- You don’t have to wait until the end of an epoch to see if training is\n",
    "  going in the right direction.  \n",
    "- You get immediate feedback on both loss and accuracy as the loop\n",
    "  progresses.  \n",
    "- Especially important for spotting problems early (e.g., loss stuck at\n",
    "  the same value, accuracy not improving).\n",
    "\n",
    "**Summary:**  \n",
    "`bar.set_postfix(...)` enriches the progress bar with real-time loss and\n",
    "accuracy, making training easier to monitor and debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e01e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T11:00:49.489587Z",
     "iopub.status.busy": "2025-09-05T11:00:49.489272Z",
     "iopub.status.idle": "2025-09-05T11:01:35.403965Z",
     "shell.execute_reply": "2025-09-05T11:01:35.402518Z"
    },
    "papermill": {
     "duration": 45.923989,
     "end_time": "2025-09-05T11:01:35.405655",
     "exception": false,
     "start_time": "2025-09-05T11:00:49.481666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/3: 100%|██████████| 968/968 [00:11<00:00, 84.42it/s, acc=0.934, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.2136, acc=0.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 968/968 [00:11<00:00, 84.61it/s, acc=0.973, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.0887, acc=0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 968/968 [00:11<00:00, 83.86it/s, acc=0.98, loss=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=0.0635, acc=0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 968/968 [00:11<00:00, 84.61it/s, acc=0.984, loss=0.0595]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss=0.0505, acc=0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "epochs = 3 \n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train() \n",
    "\n",
    "    running_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    bar = tqdm(\n",
    "        train_dl, \n",
    "        desc=f\"Epoch {epoch}/{epochs}\"\n",
    "    )\n",
    "\n",
    "    for x, y in bar:\n",
    "        # move to device and flatten \n",
    "        x = x.to(device).view(x.shape[0], 28*28)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward + loss \n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # backprop + step \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # metrics \n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1) \n",
    "        correct += (preds==y).sum().item() \n",
    "        total += y.numel() \n",
    "\n",
    "        bar.set_postfix(\n",
    "            loss=loss.item(), \n",
    "            acc=(correct / total)\n",
    "        )\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total \n",
    "    epoch_acc = correct / total \n",
    "    print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, acc={epoch_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.644633,
   "end_time": "2025-09-05T11:01:37.372392",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T11:00:28.727759",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
