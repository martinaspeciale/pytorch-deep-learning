{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88568d1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-06T11:35:56.734072Z",
     "iopub.status.busy": "2025-09-06T11:35:56.733702Z",
     "iopub.status.idle": "2025-09-06T11:36:11.909897Z",
     "shell.execute_reply": "2025-09-06T11:36:11.908509Z"
    },
    "papermill": {
     "duration": 15.182102,
     "end_time": "2025-09-06T11:36:11.911500",
     "exception": false,
     "start_time": "2025-09-06T11:35:56.729398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 49.7MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.74MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 12.5MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "\n",
    "train_mnist = torchvision.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_mnist = torchvision.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fca38b",
   "metadata": {
    "papermill": {
     "duration": 0.002519,
     "end_time": "2025-09-06T11:36:11.917231",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.914712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class: `OHMNISTGenerator`\n",
    "\n",
    "This network is not a classifier but a **generator**: it learns to produce MNIST-like digit images from one-hot class codes.\n",
    "\n",
    "### Structure\n",
    "- Inherits from `torch.nn.Module`, which allows it to define layers and be trained with PyTorch.\n",
    "- The model uses a small multilayer perceptron (MLP):\n",
    "  - Linear layer: input size 10 → hidden size 300  \n",
    "    (expects a 10-dimensional one-hot vector where each position corresponds to a digit 0–9).\n",
    "  - LeakyReLU activation: like ReLU but with a small negative slope, which prevents neurons from \"dying\" at zero output.\n",
    "  - Linear layer: hidden size 300 → output size 28×28 = 784  \n",
    "    (the flattened number of pixels in an MNIST image).\n",
    "\n",
    "### Forward pass\n",
    "- Input `x`: shape (batch_size, 10), each row is a one-hot digit vector.\n",
    "- The MLP produces an output of shape (batch_size, 784).\n",
    "- This is reshaped into (batch_size, 28, 28), so each output is a 28×28 image.\n",
    "\n",
    "### Intuition\n",
    "- The network learns a mapping from **digit labels → images**.\n",
    "- Example: input one-hot for digit \"3\" → the output should be an image resembling the digit 3.\n",
    "- This setup is essentially the reverse of a classifier: instead of predicting labels from images, it generates images from labels.\n",
    "\n",
    "### Key idea\n",
    "- Input: one-hot encoded label (10 values).\n",
    "- Output: generated MNIST-style image (28×28).\n",
    "- Purpose: demonstrate how to build a simple generator network that produces images given a class code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f829c",
   "metadata": {
    "papermill": {
     "duration": 0.002427,
     "end_time": "2025-09-06T11:36:11.922422",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.919995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Dataset: OneHotMNIST\n",
    "\n",
    "This wrapper class takes the standard MNIST dataset and modifies how each sample is returned.\n",
    "\n",
    "### Purpose\n",
    "- In the original MNIST dataset, a sample is `(image, label)`, where:\n",
    "  - `image` has shape (1, 28, 28) (channel × height × width).\n",
    "  - `label` is an integer in the range 0–9.\n",
    "- `OneHotMNIST` transforms the label into a **one-hot vector** and adjusts the image shape.\n",
    "\n",
    "### How it works\n",
    "- `__len__`: returns the number of samples in the dataset (same as the base MNIST).\n",
    "- `__getitem__(idx)`:\n",
    "  - Retrieves `(img, cls)` from the original dataset.\n",
    "  - Creates a zero vector of length 10.\n",
    "  - Sets the position corresponding to the digit class to 1 → this is the one-hot encoding.\n",
    "    - Example: if `cls = 7`, the one-hot vector is [0, 0, 0, 0, 0, 0, 0, 1, 0, 0].\n",
    "  - Returns `(one_hot_label, image)`.\n",
    "\n",
    "### Why `img[0, :, :]`?\n",
    "- Original MNIST images are shaped (1, 28, 28).\n",
    "  - The first dimension is the **channel** (MNIST is grayscale → 1 channel).\n",
    "- Taking `img[0, :, :]` removes this redundant channel dimension, giving a simpler (28, 28) array.\n",
    "- This makes sense here because we know MNIST always has one channel.\n",
    "\n",
    "### Important note\n",
    "- If you were working with RGB images (3 channels), you would **not** drop the channel dimension.\n",
    "- Keeping or removing the channel depends on how you plan to feed the images into your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2612fea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T11:36:11.929615Z",
     "iopub.status.busy": "2025-09-06T11:36:11.929163Z",
     "iopub.status.idle": "2025-09-06T11:36:11.935134Z",
     "shell.execute_reply": "2025-09-06T11:36:11.934164Z"
    },
    "papermill": {
     "duration": 0.011579,
     "end_time": "2025-09-06T11:36:11.936852",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.925273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneHotMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, cls = self.dataset[idx] \n",
    "        oh = torch.zeros(10) \n",
    "        oh[cls] = 1 \n",
    "        return oh, img[0,:,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dcd540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T11:36:11.944432Z",
     "iopub.status.busy": "2025-09-06T11:36:11.944093Z",
     "iopub.status.idle": "2025-09-06T11:36:11.951543Z",
     "shell.execute_reply": "2025-09-06T11:36:11.950240Z"
    },
    "papermill": {
     "duration": 0.013378,
     "end_time": "2025-09-06T11:36:11.953386",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.940008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OHMNISTGenerator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 300),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(300, 28*28)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        flat_output = self.mlp(x)\n",
    "        return flat_output.view(x.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9ce54",
   "metadata": {
    "papermill": {
     "duration": 0.002603,
     "end_time": "2025-09-06T11:36:11.958999",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.956396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop for the OneHotMNIST generator\n",
    "\n",
    "This block sets up and runs training for the generator model.\n",
    "\n",
    "- **tqdm**: `from tqdm import tqdm` is used to wrap the dataloader loop and display a live progress bar.  \n",
    "- **Dataset / DataLoader**:  \n",
    "  - `OneHotMNIST` wraps MNIST so that each sample is returned as (one-hot label, image).  \n",
    "  - The DataLoader batches these pairs (here, batch size = 16) and shuffles them for training.  \n",
    "- **Model**: `OHMNISTGenerator()` takes one-hot vectors as input and generates 28×28 images.  \n",
    "  - The model is moved to GPU (if available) with `.to(\"cuda\")`.  \n",
    "- **Loss function**: `MSELoss()` (mean squared error) measures the pixel-wise difference between the generated image and the real MNIST image.  \n",
    "- **Optimizer**: Adam optimizer with learning rate 0.001 updates the model’s weights.\n",
    "\n",
    "### Training loop\n",
    "- Outer loop runs for 3 epochs.  \n",
    "- Inner loop iterates over mini-batches from the DataLoader.  \n",
    "- Each batch:  \n",
    "  - `x` = one-hot labels, `y` = real images. Both moved to GPU.  \n",
    "  - Model generates an output image from `x`.  \n",
    "  - Loss is computed between generated and real images.  \n",
    "  - Optimizer step: zero gradients → backpropagate → update parameters.\n",
    "\n",
    "This process teaches the generator to reconstruct MNIST-like digit images from their one-hot class vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7570cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-06T11:36:11.965940Z",
     "iopub.status.busy": "2025-09-06T11:36:11.965568Z",
     "iopub.status.idle": "2025-09-06T11:37:38.433999Z",
     "shell.execute_reply": "2025-09-06T11:37:38.432818Z"
    },
    "papermill": {
     "duration": 86.47376,
     "end_time": "2025-09-06T11:37:38.435543",
     "exception": false,
     "start_time": "2025-09-06T11:36:11.961783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:29<00:00, 127.75it/s]\n",
      "100%|██████████| 3750/3750 [00:28<00:00, 131.33it/s]\n",
      "100%|██████████| 3750/3750 [00:28<00:00, 131.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_ds = OneHotMNIST(train_mnist)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = OHMNISTGenerator().to(device)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(0, 3):\n",
    "    for x, y in tqdm(train_dl):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.096499,
   "end_time": "2025-09-06T11:37:41.481820",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-06T11:35:50.385321",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
