{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adeaf3a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:29.470736Z",
     "iopub.status.busy": "2025-08-30T12:48:29.470472Z",
     "iopub.status.idle": "2025-08-30T12:48:29.638596Z",
     "shell.execute_reply": "2025-08-30T12:48:29.637862Z"
    },
    "papermill": {
     "duration": 0.174493,
     "end_time": "2025-08-30T12:48:29.640060",
     "exception": false,
     "start_time": "2025-08-30T12:48:29.465567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 30 12:48:29 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   36C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d294282",
   "metadata": {
    "papermill": {
     "duration": 0.002783,
     "end_time": "2025-08-30T12:48:29.646465",
     "exception": false,
     "start_time": "2025-08-30T12:48:29.643682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check for GPU access with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161f2364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:29.653223Z",
     "iopub.status.busy": "2025-08-30T12:48:29.652966Z",
     "iopub.status.idle": "2025-08-30T12:48:33.561704Z",
     "shell.execute_reply": "2025-08-30T12:48:33.561032Z"
    },
    "papermill": {
     "duration": 3.913522,
     "end_time": "2025-08-30T12:48:33.562873",
     "exception": false,
     "start_time": "2025-08-30T12:48:29.649351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e75052",
   "metadata": {
    "papermill": {
     "duration": 0.002877,
     "end_time": "2025-08-30T12:48:33.568931",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.566054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup device agnostic code\n",
    "For PyTorch run on GPU if available, else default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ecc700d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.575800Z",
     "iopub.status.busy": "2025-08-30T12:48:33.575191Z",
     "iopub.status.idle": "2025-08-30T12:48:33.579675Z",
     "shell.execute_reply": "2025-08-30T12:48:33.579138Z"
    },
    "papermill": {
     "duration": 0.00897,
     "end_time": "2025-08-30T12:48:33.580723",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.571753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5219d0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.587692Z",
     "iopub.status.busy": "2025-08-30T12:48:33.587118Z",
     "iopub.status.idle": "2025-08-30T12:48:33.608904Z",
     "shell.execute_reply": "2025-08-30T12:48:33.608373Z"
    },
    "papermill": {
     "duration": 0.026103,
     "end_time": "2025-08-30T12:48:33.609848",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.583745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of devices \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b86e19",
   "metadata": {
    "papermill": {
     "duration": 0.00345,
     "end_time": "2025-08-30T12:48:33.616393",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.612943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ## Putting tensors and models on the GPU \n",
    " Using a GPU results in faster computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea65747d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.623279Z",
     "iopub.status.busy": "2025-08-30T12:48:33.623073Z",
     "iopub.status.idle": "2025-08-30T12:48:33.662040Z",
     "shell.execute_reply": "2025-08-30T12:48:33.661375Z"
    },
    "papermill": {
     "duration": 0.043636,
     "end_time": "2025-08-30T12:48:33.663031",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.619395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3], device = \"cpu\")\n",
    "\n",
    "# tensor not on GPU \n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d221c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.670656Z",
     "iopub.status.busy": "2025-08-30T12:48:33.670447Z",
     "iopub.status.idle": "2025-08-30T12:48:33.817373Z",
     "shell.execute_reply": "2025-08-30T12:48:33.816724Z"
    },
    "papermill": {
     "duration": 0.151681,
     "end_time": "2025-08-30T12:48:33.818596",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.666915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move tensor to GPU (if available) \n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ad43f",
   "metadata": {
    "papermill": {
     "duration": 0.003084,
     "end_time": "2025-08-30T12:48:33.825050",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.821966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Moving tensors back to the CPU \n",
    "if tensor is on GPU, cannot transform it to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad3fa2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.831997Z",
     "iopub.status.busy": "2025-08-30T12:48:33.831783Z",
     "iopub.status.idle": "2025-08-30T12:48:33.834860Z",
     "shell.execute_reply": "2025-08-30T12:48:33.834318Z"
    },
    "papermill": {
     "duration": 0.007718,
     "end_time": "2025-08-30T12:48:33.835847",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.828129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c82005a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.842706Z",
     "iopub.status.busy": "2025-08-30T12:48:33.842511Z",
     "iopub.status.idle": "2025-08-30T12:48:33.848246Z",
     "shell.execute_reply": "2025-08-30T12:48:33.847733Z"
    },
    "papermill": {
     "duration": 0.010386,
     "end_time": "2025-08-30T12:48:33.849301",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.838915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix the GPU tensor with NumPy issue, we can first set it to the CPU \n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b55713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T12:48:33.856206Z",
     "iopub.status.busy": "2025-08-30T12:48:33.856024Z",
     "iopub.status.idle": "2025-08-30T12:48:33.860490Z",
     "shell.execute_reply": "2025-08-30T12:48:33.859883Z"
    },
    "papermill": {
     "duration": 0.009048,
     "end_time": "2025-08-30T12:48:33.861538",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.852490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeebbe2",
   "metadata": {
    "papermill": {
     "duration": 0.003003,
     "end_time": "2025-08-30T12:48:33.867922",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.864919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74833606",
   "metadata": {
    "papermill": {
     "duration": 0.002963,
     "end_time": "2025-08-30T12:48:33.874063",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.871100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc242b",
   "metadata": {
    "papermill": {
     "duration": 0.002963,
     "end_time": "2025-08-30T12:48:33.880109",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.877146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728783c7",
   "metadata": {
    "papermill": {
     "duration": 0.003039,
     "end_time": "2025-08-30T12:48:33.886296",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.883257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a43075",
   "metadata": {
    "papermill": {
     "duration": 0.003056,
     "end_time": "2025-08-30T12:48:33.892470",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.889414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd7a82",
   "metadata": {
    "papermill": {
     "duration": 0.002995,
     "end_time": "2025-08-30T12:48:33.899647",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.896652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1eafa",
   "metadata": {
    "papermill": {
     "duration": 0.002944,
     "end_time": "2025-08-30T12:48:33.905811",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.902867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922308c0",
   "metadata": {
    "papermill": {
     "duration": 0.002972,
     "end_time": "2025-08-30T12:48:33.911879",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.908907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6e19c",
   "metadata": {
    "papermill": {
     "duration": 0.003423,
     "end_time": "2025-08-30T12:48:33.918482",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.915059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693daf",
   "metadata": {
    "papermill": {
     "duration": 0.003004,
     "end_time": "2025-08-30T12:48:33.924562",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.921558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17761c",
   "metadata": {
    "papermill": {
     "duration": 0.003004,
     "end_time": "2025-08-30T12:48:33.930693",
     "exception": false,
     "start_time": "2025-08-30T12:48:33.927689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.556405,
   "end_time": "2025-08-30T12:48:34.953167",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-30T12:48:25.396762",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
